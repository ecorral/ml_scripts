# Copyright 2018 Eduardo R. Corral-Soto. All Rights Reserved.
#
# ==============================================================================
"""## Part 2. Load data into batches for training.

This python script implements the following functionality:
1. It opens the text file generated by the part_1.py script.
2. It loads the actual data based on the file names, and stores it in corresponding
numpy arrays.
3. It shuffles the data, while preserving the correspondences between ground-truth and labels
4. It extracts batches of data suitable for training
"""

import dicom
from dicom.errors import InvalidDicomError
import numpy as np
from PIL import Image, ImageDraw
from parsing import *
import matplotlib.pyplot as plt
import matplotlib
import glob
import re
from sklearn.utils import shuffle 
import os

os.system('cls||clear')
regex = re.compile(r'\d+')

mri_width = 256
mri_height = 256

DISPLAY_BATCHES = 0 # 0 = 'No', 1 = 'Yes'

dcm_base_folder = 'final_data/dicoms/'
contr_base_folder = 'final_data/contourfiles/'

input_list_file_name = 'filename_pairs_list.txt'

X_train = []
y_train = []

with open(input_list_file_name, 'r') as lf:
  for line in lf.readlines():
    img_file1, img_file2 = line.strip("\n").split(" ")
    
    #Parse data from files
    dcm_dict = parse_dicom_file(img_file1)
    contour_points = parse_contour_file(img_file2)
    mask = poly_to_mask(contour_points, mri_width, mri_height)

    dcm = dcm_dict['pixel_data'] 

    X_train.append(dcm)
    y_train.append(mask)

X_train = np.array(X_train)
y_train = np.array(y_train)
assert(len(X_train) == len(y_train))

num_examples = len(X_train)
print("Training Set:   {} samples".format(num_examples))

BATCH_SIZE = 8 # Number of batches = num_examples/BATCH_SIZE = 96/8 = 12
EPOCHS = 1 #10 # Number of times the entire dataset is processed forward and backward. 
        
print("Generating batches for training...")

for i in range(EPOCHS):
    #Shuffle (randomize) the whole training dataset
    X_train, y_train = shuffle(X_train, y_train)
    batch_number = 0
    for offset in range(0, num_examples, BATCH_SIZE):
        end = offset + BATCH_SIZE
        # Extract batches   
        batch_x, batch_y = X_train[offset:end], y_train[offset:end]

        batch_number = batch_number + 1

        # Here we would run a training step using these batches:
        #sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})    

        if DISPLAY_BATCHES:
          print('------------------------------------------------------------') 
          print("Batch # {} ...".format(batch_number))
          print('------------------------------------------------------------') 
          print(batch_x)
          print(batch_y)         



























      
              
